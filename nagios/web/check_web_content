#!/bin/bash

# Monitor web sites by content (pages / files). Report pageload time.
# Author: Jesus Cuenca (jcuenca@cnb.csic.es)
# See License file

. /etc/nagios/custom_scripts.cfg

readonly check_script=${custom_scripts_path}/web/check_webpage_content

# @see conf.d/services.cfg 
print_usage() {
        echo "Usage: $0 web"
        echo
}

# parse cmd arguments
if [ "$#" -gt 0 ]; then
	WEB=$1
else
	print_usage
	exit 1
fi

# You can optionally check more than 1 URL using arrays
# URLS[0]=... URLS[1]=...
# KEYPHRASES[0]= ... KEYPHRASES[1]=...

# search in hexadecimal, good for binary files
HEX=""

case $WEB in
	example1.com)
		URLS="http://www.example1.com"
		KEYPHRASES="best products optimum design"
	;;
	web2)
		URLS="http://www.web2.com"
		KEYPHRASES="Top of the shelf solutions"
	;;
	*)
		echo "Unknown site"
		exit 1
	;;
esac

I=0
STATUS=0
for URL in ${URLS[@]}; do
	KEYPHRASE=${KEYPHRASES[$I]}
	${check_script} -u "$URL" -k "$KEYPHRASE" ${HEX} 
	RESULT=$?
	(( STATUS = STATUS | RESULT ))
	(( I = I + 1 ))
done
exit $STATUS
